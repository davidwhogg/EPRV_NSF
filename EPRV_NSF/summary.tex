\documentclass[12pt, fullpage, letterpaper]{article}
\usepackage{fancyheadings, graphicx}
\setlength{\headheight}{0ex}
\setlength{\headsep}{0ex}
\input{hogg_nsf}
\renewcommand{\headrulewidth}{0pt}
\newcommand{\doi}[2]{#2}
\pagestyle{empty}

\begin{document}

\noindent
Many hundreds of exoplanets have been discovered or characterized
through extreme-precision radial-velocity (\EPRV) measurements.
The current challenge is to find
Earth-like planets on year-timescale orbits around Sun-like stars. At present, the best
published \EPRV\ programs exhibit $1\,\mps$ (ish) empirical scatter, an
order of magnitude higher than the signal of an Earth. This scatter is
not dominated by instrument calibration; 
it is largely coming from not-purely-Doppler
variability in the stellar spectrum, including surface convection and
granulation, asteroseismic pulsations, and magnetic activity.
\textbf{We propose to develop and implement principled methods for mitigating
the effects of stellar noise} by building data-driven
spectro-temporal models of stellar variability.

\textbf{Intellectual merit:}
The issue of stellar noise in \RV\ planet observations is pressing,
as multiple spectrographs are being commissioned now, and long-term
monitoring projects are starting.
These new spectrographs are beautifully designed and ultra-stable,
but without observing and analysis methods capable of
dealing with stellar variability, they will have capabilities limited
by the targets, not the hardware.

This project operates in a set of temporally overlapping stages, each
of which delivers methods, code, and refereed papers. In the First
Stage (information), the problem is to quantitatively \textbf{determine how
precisely radial velocities could in principle be measured} in the
presence of stellar variability. This novel problem can be cast as a problem
in information theory or in causal inference.
The outcome will be a principled statistical framework for the
\EPRV\ communityâ€™s ongoing efforts in data analysis.

In the Second Stage (p-modes), the proposal is to \textbf{model and mitigate
asteroseismic modes}. These modes show nearly coherent time-domain
properties and appear in the spectrum as adiabatic changes. There are
at least three methods for mitigation of asteroseismic noise: The
modes can be resolved; or the modes can be
near-cancelled by clever choice of exposure times; or the modes can be
fit out with a kind of customized non-stationary
Gaussian process. The proposal is to explore and compare these, to
produce reference implementations that work on real data, and to deliver
refereed literature documenting these and delivering recommendations.

In the Third Stage (stochastics), the project will expand its scope to
\textbf{model and mitigate variability associated with convection, granulation,
star-spots, faculae, magnetic activity, and
flares}. Each of these have expected structure in both the time and
spectral domains, which will set the causal structure of appropriate
data-driven models. The proposal is to build on success the PIs have
had in modeling \EPRV\ data with their \project{wobble} package to build these
models. Results will include open-source code and publications.

All data needed for this project are already in hand from both the
\EXPRES\ Project and extant public sources.
The proposers will operate a pair of community workshops in
Years 2 and 3 of the grant to help the community to adopt and
incorporate the findings, methods, and code produced in this project
into instrument pipelines and data-analysis stacks.

\textbf{Broader impacts:}
Operating at the interface of information theory, statistics, machine learning,
and astronomy, this project creates interdisciplinary graduate training.
The workshops will be used to propagate some of this interdisciplinarity
to early-career scientists from diverse institutions and backgrounds.
It will also experiment with developinging better workshop practices for our home institutions.
This project will be performed in a fully open mode, operating on
public data, delivering open-source code, and generating public
high-level data products, enabling new investigations by anyone.

\end{document}
